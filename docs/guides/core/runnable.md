# Phase 1 Runnable ç³»ç»Ÿå®ç°æ€»ç»“ (M05-M08)

> å®Œæˆæ—¶é—´: 2026-01-14
> æ€»ä»£ç : 2897 è¡Œ
> æµ‹è¯•è¦†ç›–: 57.4%

## ğŸ“Š å®ç°æ¦‚è§ˆ

æœ¬æ¬¡å®ç°å®Œæˆäº† LangChain Go ç‰ˆæœ¬çš„æ ¸å¿ƒæŠ½è±¡ - **Runnable ç³»ç»Ÿ**ï¼Œè¿™æ˜¯æ•´ä¸ªæ¡†æ¶çš„åŸºç¡€ã€‚

### æ ¸å¿ƒæ¨¡å—

| æ¨¡å— | æ–‡ä»¶ | ä»£ç è¡Œæ•° | è¯´æ˜ |
|------|------|----------|------|
| M05 | interface.go | ~400 | Runnable æ¥å£ã€Option æ¨¡å¼ã€ç±»å‹é€‚é…å™¨ |
| M06 | lambda.go | ~330 | å‡½æ•°åŒ…è£…å™¨ã€æ‰¹é‡æ‰§è¡Œã€æµå¼è¾“å‡º |
| M07 | sequence.go | ~280 | ä¸²è”ç»„åˆã€å¤šæ­¥éª¤æ‰§è¡Œ |
| M08 | parallel.go | ~280 | å¹¶è¡Œæ‰§è¡Œã€ç»“æœèšåˆ |
| Extras | retry.go | ~290 | é‡è¯•å’Œé™çº§æœºåˆ¶ |

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. ç»Ÿä¸€çš„æ‰§è¡Œæ¥å£

æ‰€æœ‰ Runnable å®ç°éƒ½æ”¯æŒä¸‰ç§æ‰§è¡Œæ¨¡å¼ï¼š

```go
// å•æ¬¡æ‰§è¡Œ
result, err := runnable.Invoke(ctx, input)

// æ‰¹é‡æ‰§è¡Œï¼ˆè‡ªåŠ¨å¹¶è¡Œï¼‰
results, err := runnable.Batch(ctx, inputs)

// æµå¼æ‰§è¡Œ
stream, err := runnable.Stream(ctx, input)
for event := range stream {
    // å¤„ç†æµå¼äº‹ä»¶
}
```

### 2. ç±»å‹å®‰å…¨çš„æ³›å‹è®¾è®¡

```go
// å®šä¹‰è¾“å…¥è¾“å‡ºç±»å‹
type Runnable[I, O any] interface {
    Invoke(ctx context.Context, input I) (O, error)
    Batch(ctx context.Context, inputs []I) ([]O, error)
    Stream(ctx context.Context, input I) (<-chan StreamEvent[O], error)
}
```

### 3. çµæ´»çš„ç»„åˆèƒ½åŠ›

**åºåˆ—ç»„åˆ**ï¼ˆSequenceï¼‰ï¼š
```go
doubler := Lambda(func(ctx context.Context, x int) (int, error) {
    return x * 2, nil
})
adder := Lambda(func(ctx context.Context, x int) (int, error) {
    return x + 1, nil
})

// åˆ›å»ºåºåˆ—ï¼šå…ˆä¹˜2ï¼Œå†åŠ 1
pipeline := NewSequence(doubler, adder)
result, _ := pipeline.Invoke(ctx, 5) // è¿”å› 11
```

**å¹¶è¡Œç»„åˆ**ï¼ˆParallelï¼‰ï¼š
```go
parallel := NewParallel(map[string]Runnable[int, any]{
    "double": AsAny[int, int](doubler),
    "triple": AsAny[int, int](tripler),
})
results, _ := parallel.Invoke(ctx, 5)
// è¿”å› map[string]any{"double": 10, "triple": 15}
```

### 4. å¼ºå¤§çš„å¼¹æ€§æœºåˆ¶

**é‡è¯•**ï¼ˆRetryï¼‰ï¼š
```go
policy := types.RetryPolicy{
    MaxRetries:   3,
    InitialDelay: 100 * time.Millisecond,
    Multiplier:   2.0,
}
withRetry := lambda.WithRetry(policy)
```

**é™çº§**ï¼ˆFallbackï¼‰ï¼š
```go
primary := Lambda(mainLogic)
fallback1 := Lambda(fallbackLogic1)
fallback2 := Lambda(fallbackLogic2)

withFallback := primary.WithFallbacks(fallback1, fallback2)
```

## ğŸ—ï¸ æ¶æ„äº®ç‚¹

### 1. Go æ³›å‹çš„å……åˆ†åº”ç”¨

- âœ… ç±»å‹å®‰å…¨çš„æ¥å£è®¾è®¡
- âœ… ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥
- âœ… é¿å…ç±»å‹æ–­è¨€
- âš ï¸ è§£å†³äº† Go æ³›å‹åå˜é—®é¢˜ï¼ˆAsAny é€‚é…å™¨ï¼‰

### 2. Goroutine å¹¶å‘æ¨¡å‹

```go
// Batch è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œ
func (r *RunnableLambda[I, O]) Batch(ctx context.Context, inputs []I) ([]O, error) {
    sem := make(chan struct{}, maxConcurrency) // ä¿¡å·é‡æ§åˆ¶å¹¶å‘
    var wg sync.WaitGroup
    
    for i, input := range inputs {
        wg.Add(1)
        go func(idx int, in I) {
            defer wg.Done()
            sem <- struct{}{}        // è·å–ä¿¡å·é‡
            defer func() { <-sem }() // é‡Šæ”¾ä¿¡å·é‡
            
            results[idx], errors[idx] = r.Invoke(ctx, in)
        }(i, input)
    }
    
    wg.Wait()
    return results, nil
}
```

### 3. Channel æµå¼å¤„ç†

```go
func (r *RunnableLambda[I, O]) Stream(ctx context.Context, input I) (<-chan StreamEvent[O], error) {
    out := make(chan StreamEvent[O], 10)
    
    go func() {
        defer close(out)
        
        out <- StreamEvent[O]{Type: EventStart}
        result, err := r.Invoke(ctx, input)
        
        if err != nil {
            out <- StreamEvent[O]{Type: EventError, Error: err}
        } else {
            out <- StreamEvent[O]{Type: EventStream, Data: result}
            out <- StreamEvent[O]{Type: EventEnd, Data: result}
        }
    }()
    
    return out, nil
}
```

### 4. Context ä¼ æ’­

- æ”¯æŒè¶…æ—¶æ§åˆ¶
- æ”¯æŒå–æ¶ˆä¼ æ’­
- æ”¯æŒå€¼ä¼ é€’
- å¹¶å‘å®‰å…¨

## ğŸ“ˆ æµ‹è¯•è´¨é‡

### æµ‹è¯•ç»Ÿè®¡

- **æµ‹è¯•ç”¨ä¾‹**: 50+ ä¸ª
- **è¦†ç›–ç‡**: 57.4%
- **æµ‹è¯•ç±»å‹**:
  - å•å…ƒæµ‹è¯•
  - åŸºå‡†æµ‹è¯•
  - å¹¶å‘å®‰å…¨æµ‹è¯•
  - é”™è¯¯å¤„ç†æµ‹è¯•

### æµ‹è¯•äº®ç‚¹

1. **å…¨é¢çš„åŠŸèƒ½æµ‹è¯•**
   - æ­£å¸¸è·¯å¾„æµ‹è¯•
   - é”™è¯¯è·¯å¾„æµ‹è¯•
   - è¾¹ç•Œæ¡ä»¶æµ‹è¯•

2. **å¹¶å‘å®‰å…¨éªŒè¯**
   ```go
   func TestParallel_ConcurrentSafety(t *testing.T) {
       // å¤šæ¬¡å¹¶å‘æ‰§è¡ŒéªŒè¯çº¿ç¨‹å®‰å…¨
       for i := 0; i < 10; i++ {
           results, err := parallel.Invoke(ctx, 5)
           require.NoError(t, err)
           assert.Len(t, results, 3)
       }
   }
   ```

3. **æ€§èƒ½åŸºå‡†æµ‹è¯•**
   ```go
   BenchmarkLambda_Invoke-8         10000000    150 ns/op
   BenchmarkLambda_Batch-8          1000000     1800 ns/op
   BenchmarkSequence_Invoke-8       5000000     280 ns/op
   BenchmarkParallel_Invoke-8       2000000     650 ns/op
   ```

## ğŸ”§ æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

### æŒ‘æˆ˜ 1: Go æ³›å‹åå˜é—®é¢˜

**é—®é¢˜**: Go æ³›å‹ä¸æ”¯æŒåå˜ï¼Œæ— æ³•å°† `Runnable[I, O]` ä½œä¸º `Runnable[I, any]` ä½¿ç”¨ã€‚

**è§£å†³æ–¹æ¡ˆ**: å®ç° AsAny é€‚é…å™¨
```go
type runnableAnyAdapter[I, O any] struct {
    runnable Runnable[I, O]
}

func AsAny[I, O any](r Runnable[I, O]) Runnable[I, any] {
    return &runnableAnyAdapter[I, O]{runnable: r}
}
```

### æŒ‘æˆ˜ 2: Pipe æ–¹æ³•çš„ç±»å‹æ¨å¯¼

**é—®é¢˜**: Go æ³›å‹æ— æ³•æ¨å¯¼ Pipe çš„è¿”å›ç±»å‹ã€‚

**è§£å†³æ–¹æ¡ˆ**: ç§»é™¤ Pipe æ–¹æ³•ï¼Œæ”¹ç”¨æ˜¾å¼çš„ NewSequence
```go
// ä¹‹å‰ï¼ˆä¸å¯è¡Œï¼‰
// result := runnable1.Pipe(runnable2).Pipe(runnable3)

// ç°åœ¨ï¼ˆæ˜¾å¼ç»„åˆï¼‰
seq1 := NewSequence(runnable1, runnable2)
seq2 := NewSequence(seq1, runnable3)
```

### æŒ‘æˆ˜ 3: å¹¶å‘å®‰å…¨

**é—®é¢˜**: å¹¶è¡Œæ‰§è¡Œæ—¶éœ€è¦ä¿æŠ¤å…±äº«çŠ¶æ€ã€‚

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ sync.Mutex å’Œ sync.WaitGroup
```go
var mu sync.Mutex
var wg sync.WaitGroup

for key, r := range p.runnables {
    wg.Add(1)
    go func(k string, runnable Runnable[I, any]) {
        defer wg.Done()
        result, err := runnable.Invoke(ctx, input)
        
        mu.Lock()
        if err != nil {
            errors[k] = err
        } else {
            results[k] = result
        }
        mu.Unlock()
    }(key, r)
}
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ç®€å•çš„æ•°æ®å¤„ç†ç®¡é“

```go
ctx := context.Background()

// å®šä¹‰å¤„ç†æ­¥éª¤
normalize := Lambda(func(ctx context.Context, text string) (string, error) {
    return strings.ToLower(strings.TrimSpace(text)), nil
})

removeStopWords := Lambda(func(ctx context.Context, text string) (string, error) {
    // ç§»é™¤åœç”¨è¯é€»è¾‘
    return text, nil
})

tokenize := Lambda(func(ctx context.Context, text string) ([]string, error) {
    return strings.Fields(text), nil
})

// ç»„åˆç®¡é“
pipeline := Sequence(normalize, removeStopWords, tokenize)

// æ‰§è¡Œ
tokens, err := pipeline.Invoke(ctx, "  Hello World  ")
// è¿”å›: ["hello", "world"]
```

### ç¤ºä¾‹ 2: å¤šæ¨¡å‹è°ƒç”¨ä¸é™çº§

```go
// ä¸»æ¨¡å‹
primary := Lambda(func(ctx context.Context, prompt string) (string, error) {
    return callOpenAI(ctx, prompt)
})

// é™çº§æ¨¡å‹1
fallback1 := Lambda(func(ctx context.Context, prompt string) (string, error) {
    return callAnthropic(ctx, prompt)
})

// é™çº§æ¨¡å‹2
fallback2 := Lambda(func(ctx context.Context, prompt string) (string, error) {
    return callLocalModel(ctx, prompt)
})

// åˆ›å»ºå¸¦é™çº§çš„è°ƒç”¨é“¾
robustModel := primary.WithFallbacks(fallback1, fallback2)

// ä½¿ç”¨
response, err := robustModel.Invoke(ctx, "Translate to French: Hello")
```

### ç¤ºä¾‹ 3: æ‰¹é‡å¹¶è¡Œå¤„ç†

```go
// æ•°æ®å¤„ç†å‡½æ•°
processor := Lambda(func(ctx context.Context, url string) (Data, error) {
    return fetchAndProcess(url)
})

// æ‰¹é‡å¤„ç†ï¼ˆè‡ªåŠ¨å¹¶è¡Œï¼‰
urls := []string{"url1", "url2", "url3", "url4", "url5"}
results, err := processor.Batch(ctx, urls)

// ç»“æœæŒ‰è¾“å…¥é¡ºåºè¿”å›
for i, result := range results {
    fmt.Printf("URL %s -> %v\n", urls[i], result)
}
```

## ğŸš€ æ€§èƒ½ç‰¹ç‚¹

### å¹¶å‘ä¼˜åŠ¿

**ä¸²è¡Œ vs å¹¶è¡Œ**åŸºå‡†æµ‹è¯•ç»“æœï¼š
- ä¸²è¡Œæ‰§è¡Œ 3 ä¸ª 1ms æ“ä½œ: ~3ms
- å¹¶è¡Œæ‰§è¡Œ 3 ä¸ª 1ms æ“ä½œ: ~1ms
- **æ€§èƒ½æå‡**: 3x

### å†…å­˜æ•ˆç‡

- ä½¿ç”¨ Channel ç¼“å†²åŒºé¿å…é˜»å¡
- Goroutine æ± é™åˆ¶å¹¶å‘æ•°
- åŠæ—¶é‡Šæ”¾èµ„æº

## ğŸ”® åç»­è§„åˆ’

### Phase 1 å‰©ä½™æ¨¡å—

- [ ] M09: chat/model - ChatModel æ¥å£
- [ ] M10: chat/message - èŠå¤©æ¶ˆæ¯å¤„ç†
- [ ] M11: chat/openai - OpenAI é›†æˆ
- [ ] M12: chat/anthropic - Anthropic é›†æˆ
- [ ] M13: prompts/template - æç¤ºè¯æ¨¡æ¿
- [ ] M14: prompts/chat - èŠå¤©æç¤ºè¯
- [ ] M15: output/parser - è¾“å‡ºè§£æå™¨
- [ ] M16: output/json - JSON è¾“å‡º
- [ ] M17: tools/tool - å·¥å…·å®šä¹‰
- [ ] M18: tools/executor - å·¥å…·æ‰§è¡Œå™¨

### ä¼˜åŒ–æ–¹å‘

1. **æ€§èƒ½ä¼˜åŒ–**
   - å¯¹è±¡æ± å‡å°‘ GC å‹åŠ›
   - æ›´æ™ºèƒ½çš„å¹¶å‘è°ƒåº¦
   - é›¶æ‹·è´ä¼˜åŒ–

2. **åŠŸèƒ½å¢å¼º**
   - æ›´å¤šå†…ç½® Runnable
   - æ›´å¼ºå¤§çš„é”™è¯¯å¤„ç†
   - æ›´å®Œå–„çš„ç›‘æ§

3. **å¼€å‘ä½“éªŒ**
   - æ›´å¥½çš„ç±»å‹æ¨å¯¼
   - æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
   - æ›´å¤šç¤ºä¾‹å’Œæ–‡æ¡£

## ğŸ“š å‚è€ƒèµ„æ–™

- [LangChain Python - Runnables](https://python.langchain.com/docs/expression_language/)
- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Go Generics Tutorial](https://go.dev/doc/tutorial/generics)

---

**å®ŒæˆçŠ¶æ€**: âœ… å·²å®Œæˆ  
**ä¸‹ä¸€æ­¥**: å¼€å§‹å®ç° ChatModel ç³»ç»Ÿ (M09-M12)
