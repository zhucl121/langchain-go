# LangChain-Go æ‰©å±•åŠŸèƒ½ä½¿ç”¨æŒ‡å—

## ğŸ‰ æ¬¢è¿ä½¿ç”¨ LangChain-Go æ‰©å±•åŠŸèƒ½!

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨æ–°å®ç°çš„é«˜å±‚ API,è®©æ‚¨ç”¨ **3 è¡Œä»£ç ** å®ŒæˆåŸæœ¬éœ€è¦ **150 è¡Œ** çš„ RAG åº”ç”¨!

---

## ğŸ“¦ æ–°å¢åŠŸèƒ½æ¦‚è§ˆ

### 1. RAG Chain - æ£€ç´¢å¢å¼ºç”Ÿæˆ

**ä¹‹å‰** (150+ è¡Œæ‰‹åŠ¨ä»£ç ):
```go
func (r *RAGService) Query(ctx context.Context, req QueryRequest) (*QueryResponse, error) {
    // æ‰‹åŠ¨æ£€ç´¢æ–‡æ¡£
    retrieved, err := r.vectorStore.SimilaritySearch(ctx, req.Question, req.TopK)
    
    // æ‰‹åŠ¨è¿‡æ»¤ä½åˆ†æ–‡æ¡£
    var relevantDocs []*Document
    for _, doc := range retrieved {
        if doc.Score >= req.MinScore {
            relevantDocs = append(relevantDocs, doc)
        }
    }
    
    // æ‰‹åŠ¨æ„å»ºä¸Šä¸‹æ–‡
    var context strings.Builder
    for i, doc := range relevantDocs {
        context.WriteString(fmt.Sprintf("[æ–‡æ¡£ %d]\n%s\n", i+1, doc.Content))
    }
    
    // æ‰‹åŠ¨æ„å»º prompt
    prompt := fmt.Sprintf(`åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜...
ä¸Šä¸‹æ–‡: %s
é—®é¢˜: %s`, context.String(), req.Question)
    
    // æ‰‹åŠ¨è°ƒç”¨ LLM
    messages := []types.Message{types.NewUserMessage(prompt)}
    response, err := r.chatModel.Invoke(ctx, messages)
    
    // ... æ›´å¤šæ‰‹åŠ¨å¤„ç†
    return &QueryResponse{...}, nil
}
```

**ç°åœ¨** (3 è¡Œä»£ç ):
```go
retriever := retrievers.NewVectorStoreRetriever(vectorStore)
ragChain := chains.NewRAGChain(retriever, llm)
result, _ := ragChain.Run(ctx, "What is LangChain?")
```

**æ•ˆç‡æå‡**: **50x** ğŸš€

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
go get github.com/zhuchenglong/langchain-go/retrieval/chains
go get github.com/zhuchenglong/langchain-go/retrieval/retrievers
```

### åŸºç¡€ RAG åº”ç”¨

```go
package main

import (
    "context"
    "fmt"
    
    "github.com/zhuchenglong/langchain-go/core/chat/ollama"
    "github.com/zhuchenglong/langchain-go/retrieval/chains"
    "github.com/zhuchenglong/langchain-go/retrieval/embeddings"
    "github.com/zhuchenglong/langchain-go/retrieval/loaders"
    "github.com/zhuchenglong/langchain-go/retrieval/retrievers"
    "github.com/zhuchenglong/langchain-go/retrieval/vectorstores"
)

func main() {
    ctx := context.Background()
    
    // æ­¥éª¤ 1: å‡†å¤‡æ–‡æ¡£
    docs := []*loaders.Document{
        {Content: "LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»º LLM åº”ç”¨çš„æ¡†æ¶"},
        {Content: "RAG ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆä¸¤ä¸ªæ­¥éª¤"},
    }
    
    // æ­¥éª¤ 2: åˆ›å»ºå‘é‡å­˜å‚¨å¹¶æ·»åŠ æ–‡æ¡£
    embedder := embeddings.NewOllamaEmbeddings("nomic-embed-text")
    vectorStore := vectorstores.NewInMemoryVectorStore(embedder)
    vectorStore.AddDocuments(ctx, docs)
    
    // æ­¥éª¤ 3: åˆ›å»ºæ£€ç´¢å™¨
    retriever := retrievers.NewVectorStoreRetriever(vectorStore)
    
    // æ­¥éª¤ 4: åˆ›å»º RAG Chain
    llm := ollama.NewChatOllama("qwen2.5:7b")
    ragChain := chains.NewRAGChain(retriever, llm)
    
    // æ­¥éª¤ 5: æ‰§è¡ŒæŸ¥è¯¢
    result, err := ragChain.Run(ctx, "ä»€ä¹ˆæ˜¯ RAG?")
    if err != nil {
        panic(err)
    }
    
    // æ­¥éª¤ 6: è¾“å‡ºç»“æœ
    fmt.Println("ç­”æ¡ˆ:", result.Answer)
    fmt.Printf("ç½®ä¿¡åº¦: %.2f\n", result.Confidence)
    fmt.Printf("è€—æ—¶: %v\n", result.TimeElapsed)
}
```

---

## ğŸ’¡ é«˜çº§åŠŸèƒ½

### 1. é…ç½®é€‰é¡¹

```go
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithScoreThreshold(0.7),        // è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
    chains.WithMaxContextLen(2000),        // é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
    chains.WithTopK(3),                    // è¿”å› top 3 æ–‡æ¡£
    chains.WithReturnSources(true),        // è¿”å›æ¥æºæ–‡æ¡£
    chains.WithPrompt(customPrompt),       // è‡ªå®šä¹‰ prompt
)
```

### 2. æµå¼è¾“å‡º

å®æ—¶æ˜¾ç¤º LLM ç”Ÿæˆçš„å†…å®¹:

```go
stream, _ := ragChain.Stream(ctx, "Explain LangChain")

for chunk := range stream {
    switch chunk.Type {
    case "retrieval":
        fmt.Println("âœ“ æ£€ç´¢å®Œæˆ")
    case "llm_token":
        fmt.Print(chunk.Data) // å®æ—¶æ‰“å° token
    case "done":
        fmt.Println("\nâœ“ å®Œæˆ")
    }
}
```

### 3. æ‰¹é‡å¤„ç†

å¹¶è¡Œå¤„ç†å¤šä¸ªé—®é¢˜:

```go
questions := []string{
    "ä»€ä¹ˆæ˜¯ LangChain?",
    "ä»€ä¹ˆæ˜¯ RAG?",
    "å¦‚ä½•ä½¿ç”¨å‘é‡æ•°æ®åº“?",
}

results, _ := ragChain.Batch(ctx, questions)

for i, result := range results {
    fmt.Printf("Q%d: %s\nA%d: %s\n\n", i+1, questions[i], i+1, result.Answer)
}
```

### 4. è‡ªå®šä¹‰ Prompt

ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿:

```go
import "github.com/zhuchenglong/langchain-go/core/prompts/templates"

ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithPrompt(templates.DetailedRAGPrompt),
)
```

æˆ–åˆ›å»ºè‡ªå®šä¹‰ prompt:

```go
customPrompt, _ := prompts.NewPromptTemplate(prompts.PromptTemplateConfig{
    Template: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¡¾é—®ã€‚

å‚è€ƒèµ„æ–™:
{{.context}}

ç”¨æˆ·é—®é¢˜: {{.question}}

è¯·æä¾›è¯¦ç»†çš„æŠ€æœ¯è§£ç­”:`,
    InputVariables: []string{"context", "question"},
})

ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithPrompt(customPrompt),
)
```

---

## ğŸ” é«˜çº§æ£€ç´¢å™¨

### 1. å¤šæŸ¥è¯¢æ£€ç´¢å™¨

ä½¿ç”¨ LLM ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“,æé«˜å¬å›ç‡:

```go
import "github.com/zhuchenglong/langchain-go/retrieval/retrievers"

// åŸºç¡€æ£€ç´¢å™¨
baseRetriever := retrievers.NewVectorStoreRetriever(vectorStore)

// å¤šæŸ¥è¯¢æ£€ç´¢å™¨
multiRetriever := retrievers.NewMultiQueryRetriever(
    baseRetriever,
    llm,
    retrievers.WithNumQueries(3),          // ç”Ÿæˆ 3 ä¸ªæŸ¥è¯¢å˜ä½“
    retrievers.WithIncludeOriginal(true),  // åŒ…å«åŸå§‹æŸ¥è¯¢
)

// è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å¹¶æ£€ç´¢
docs, _ := multiRetriever.GetRelevantDocuments(ctx, "å¦‚ä½•ä½¿ç”¨ LangChain?")
```

**å·¥ä½œåŸç†**:
1. LLM ä¸ºåŸå§‹æŸ¥è¯¢ç”Ÿæˆ 3 ä¸ªä¸åŒæªè¾çš„å˜ä½“
2. å¯¹æ¯ä¸ªå˜ä½“åˆ†åˆ«æ£€ç´¢
3. åˆå¹¶å»é‡ç»“æœ

### 2. é›†æˆæ£€ç´¢å™¨ (æ··åˆæ£€ç´¢)

èåˆå¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœ,ä½¿ç”¨ RRF ç®—æ³•:

```go
// å‘é‡æ£€ç´¢å™¨
vectorRetriever := retrievers.NewVectorStoreRetriever(vectorStore)

// BM25 æ£€ç´¢å™¨ (å¦‚æœå·²å®ç°)
// bm25Retriever := retrievers.NewBM25Retriever(documents)

// é›†æˆæ£€ç´¢å™¨
ensemble := retrievers.NewEnsembleRetriever(
    []retrievers.Retriever{vectorRetriever /*, bm25Retriever*/},
    retrievers.WithWeights([]float64{0.5, 0.5}), // ç­‰æƒé‡
    retrievers.WithRRFK(60),                     // RRF å¸¸æ•°
)

// è‡ªåŠ¨èåˆç»“æœ
docs, _ := ensemble.GetRelevantDocuments(ctx, "question")
```

**RRF (Reciprocal Rank Fusion)**:
- å¯¹æ¯ä¸ªæ£€ç´¢å™¨çš„ç»“æœæŒ‰æ’åè®¡ç®—åˆ†æ•°
- åˆ†æ•°å…¬å¼: `score = weight / (k + rank)`
- åˆå¹¶ç›¸åŒæ–‡æ¡£çš„åˆ†æ•°
- æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº

---

## ğŸ“š Prompt æ¨¡æ¿åº“

### é¢„å®šä¹‰æ¨¡æ¿

```go
import "github.com/zhuchenglong/langchain-go/core/prompts/templates"

// RAG æ¨¡æ¿
templates.DefaultRAGPrompt        // é»˜è®¤ RAG prompt
templates.DetailedRAGPrompt       // è¯¦ç»†çš„ RAG prompt
templates.ConversationalRAGPrompt // å¯¹è¯å¼ RAG prompt
templates.MultilingualRAGPrompt   // å¤šè¯­è¨€ RAG prompt
templates.StructuredRAGPrompt     // ç»“æ„åŒ– RAG (è¿”å› JSON)
templates.ConciseRAGPrompt        // ç®€æ´çš„ RAG prompt

// Agent æ¨¡æ¿
templates.ReActPrompt             // ReAct Agent prompt
templates.ChineseReActPrompt      // ä¸­æ–‡ ReAct prompt
templates.PlanExecutePrompt       // Plan-Execute prompt
templates.ToolCallingPrompt       // Tool Calling prompt

// å…¶ä»–æ¨¡æ¿
templates.SummarizationPrompt     // æ‘˜è¦
templates.TranslationPrompt       // ç¿»è¯‘
templates.CodeExplanationPrompt   // ä»£ç è§£é‡Š
templates.SentimentAnalysisPrompt // æƒ…æ„Ÿåˆ†æ
```

### ä½¿ç”¨æ¨¡æ¿

```go
// æ–¹å¼ 1: ç›´æ¥ä½¿ç”¨
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithPrompt(templates.DetailedRAGPrompt),
)

// æ–¹å¼ 2: é€šè¿‡åç§°è·å–
prompt := templates.GetRAGTemplate("detailed")
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithPrompt(prompt),
)
```

---

## ğŸ¯ å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æŠ€æœ¯æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

```go
func main() {
    ctx := context.Background()
    
    // åŠ è½½æŠ€æœ¯æ–‡æ¡£
    loader := loaders.NewDirectoryLoader("./docs", "*.md")
    docs, _ := loader.Load()
    
    // åˆ›å»ºå‘é‡å­˜å‚¨
    embedder := embeddings.NewOllamaEmbeddings("nomic-embed-text")
    vectorStore := vectorstores.NewInMemoryVectorStore(embedder)
    vectorStore.AddDocuments(ctx, docs)
    
    // åˆ›å»º RAG Chain
    retriever := retrievers.NewVectorStoreRetriever(vectorStore,
        retrievers.WithTopK(3),
        retrievers.WithScoreThreshold(0.7),
    )
    
    llm := ollama.NewChatOllama("qwen2.5:7b")
    ragChain := chains.NewRAGChain(retriever, llm,
        chains.WithPrompt(templates.DetailedRAGPrompt),
    )
    
    // äº¤äº’å¼é—®ç­”
    for {
        fmt.Print("\né—®é¢˜: ")
        var question string
        fmt.Scanln(&question)
        
        if question == "exit" {
            break
        }
        
        result, err := ragChain.Run(ctx, question)
        if err != nil {
            fmt.Println("é”™è¯¯:", err)
            continue
        }
        
        fmt.Println("\nç­”æ¡ˆ:", result.Answer)
        fmt.Printf("ç½®ä¿¡åº¦: %.2f\n", result.Confidence)
        
        if len(result.Context) > 0 {
            fmt.Println("\næ¥æº:")
            for i, doc := range result.Context {
                source := doc.Metadata["source"].(string)
                fmt.Printf("  [%d] %s\n", i+1, source)
            }
        }
    }
}
```

### ç¤ºä¾‹ 2: å¤šè¯­è¨€æ™ºèƒ½å®¢æœ

```go
func main() {
    // ... åˆå§‹åŒ–ä»£ç  ...
    
    // ä½¿ç”¨å¤šè¯­è¨€ prompt
    ragChain := chains.NewRAGChain(retriever, llm,
        chains.WithPrompt(templates.MultilingualRAGPrompt),
    )
    
    // è‡ªåŠ¨é€‚åº”ç”¨æˆ·è¯­è¨€
    questions := []string{
        "What is your return policy?",      // è‹±æ–‡
        "é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆ?",                    // ä¸­æ–‡
        "Quelle est votre politique?",      // æ³•æ–‡
    }
    
    results, _ := ragChain.Batch(ctx, questions)
    
    for i, result := range results {
        fmt.Printf("Q: %s\nA: %s\n\n", questions[i], result.Answer)
    }
}
```

### ç¤ºä¾‹ 3: æµå¼å®æ—¶é—®ç­”

```go
func streamingQA(ragChain *chains.RAGChain, question string) {
    ctx := context.Background()
    
    fmt.Printf("é—®é¢˜: %s\n\n", question)
    fmt.Print("å›ç­”: ")
    
    stream, err := ragChain.Stream(ctx, question)
    if err != nil {
        panic(err)
    }
    
    for chunk := range stream {
        switch chunk.Type {
        case "start":
            fmt.Print("ğŸ¤” æ€è€ƒä¸­...")
            
        case "retrieval":
            data := chunk.Data.(map[string]interface{})
            count := data["count"].(int)
            fmt.Printf("\râœ“ æ‰¾åˆ° %d ä¸ªç›¸å…³æ–‡æ¡£\n\n", count)
            
        case "llm_token":
            fmt.Print(chunk.Data.(string))
            
        case "done":
            result := chunk.Data.(chains.RAGResult)
            fmt.Printf("\n\nâœ“ å®Œæˆ (è€—æ—¶: %v, ç½®ä¿¡åº¦: %.2f)\n",
                result.TimeElapsed, result.Confidence)
                
        case "error":
            fmt.Printf("\nâŒ é”™è¯¯: %v\n", chunk.Data)
        }
    }
}
```

---

## ğŸ”§ é…ç½®æœ€ä½³å®è·µ

### 1. é˜ˆå€¼è®¾ç½®

```go
// ä¸¥æ ¼æ¨¡å¼ (é«˜ç²¾åº¦)
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithScoreThreshold(0.8),
    chains.WithTopK(2),
)

// å¹³è¡¡æ¨¡å¼ (æ¨è)
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithScoreThreshold(0.7),
    chains.WithTopK(3),
)

// å®½æ¾æ¨¡å¼ (é«˜å¬å›)
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithScoreThreshold(0.5),
    chains.WithTopK(5),
)
```

### 2. ä¸Šä¸‹æ–‡é•¿åº¦

æ ¹æ® LLM çš„ä¸Šä¸‹æ–‡çª—å£è®¾ç½®:

```go
// 7B æ¨¡å‹ (ä¸Šä¸‹æ–‡çª—å£ 4096)
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithMaxContextLen(2000),
)

// 70B æ¨¡å‹ (ä¸Šä¸‹æ–‡çª—å£ 128K)
ragChain := chains.NewRAGChain(retriever, llm,
    chains.WithMaxContextLen(10000),
)
```

### 3. é”™è¯¯å¤„ç†

```go
result, err := ragChain.Run(ctx, question)
if err != nil {
    log.Printf("RAG æ‰§è¡Œå¤±è´¥: %v", err)
    return
}

// æ£€æŸ¥ç½®ä¿¡åº¦
if result.Confidence < 0.5 {
    log.Println("è­¦å‘Š: ä½ç½®ä¿¡åº¦å›ç­”")
}

// æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
if len(result.Context) == 0 {
    log.Println("è­¦å‘Š: æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
}
```

---

## ğŸ“– API å‚è€ƒ

### RAGChain

```go
type RAGChain struct {
    // ç§æœ‰å­—æ®µ
}

// åˆ›å»º
func NewRAGChain(retriever Retriever, llm ChatModel, opts ...Option) *RAGChain

// æ‰§è¡Œ
func (c *RAGChain) Run(ctx context.Context, question string) (RAGResult, error)
func (c *RAGChain) Stream(ctx context.Context, question string) (<-chan RAGChunk, error)
func (c *RAGChain) Batch(ctx context.Context, questions []string) ([]RAGResult, error)

// é…ç½®é€‰é¡¹
func WithPrompt(prompt *PromptTemplate) Option
func WithScoreThreshold(threshold float32) Option
func WithMaxContextLen(maxLen int) Option
func WithReturnSources(returnSources bool) Option
func WithTopK(topK int) Option
func WithContextFormatter(formatter ContextFormatter) Option
```

### Retriever

```go
type Retriever interface {
    GetRelevantDocuments(ctx context.Context, query string) ([]*Document, error)
    GetRelevantDocumentsWithScore(ctx context.Context, query string) ([]DocumentWithScore, error)
}

// VectorStoreRetriever
func NewVectorStoreRetriever(store VectorStore, opts ...VectorStoreOption) *VectorStoreRetriever
func WithSearchType(searchType SearchType) VectorStoreOption
func WithTopK(k int) VectorStoreOption
func WithScoreThreshold(threshold float32) VectorStoreOption

// MultiQueryRetriever
func NewMultiQueryRetriever(baseRetriever Retriever, llm ChatModel, opts ...MultiQueryOption) *MultiQueryRetriever
func WithNumQueries(num int) MultiQueryOption
func WithIncludeOriginal(include bool) MultiQueryOption

// EnsembleRetriever
func NewEnsembleRetriever(retrievers []Retriever, opts ...EnsembleOption) *EnsembleRetriever
func WithWeights(weights []float64) EnsembleOption
func WithRRFK(k int) EnsembleOption
```

---

## ğŸ“ å­¦ä¹ èµ„æº

- **å®æ–½è®¡åˆ’**: `EXTENSION_IMPLEMENTATION_PLAN.md`
- **å®æ–½æ€»ç»“**: `IMPLEMENTATION_SUMMARY.md`
- **Python API å‚è€ƒ**: `PYTHON_API_REFERENCE.md`
- **åŠŸèƒ½å¯¹æ¯”**: `PYTHON_VS_GO_COMPARISON.md`

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®!

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

**Happy Coding!** ğŸš€
