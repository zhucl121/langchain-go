# LangChain-Go v0.5.0 å®æ–½è®¡åˆ’

**ç‰ˆæœ¬**: v0.5.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-01-20  
**åŸºå‡†ç‰ˆæœ¬**: v0.4.2 (å¾…å®Œæˆ)  
**ä¸»é¢˜**: åˆ†å¸ƒå¼éƒ¨ç½² - é›†ç¾¤æ”¯æŒä¸è´Ÿè½½å‡è¡¡

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

v0.4.2 å°†å®Œæˆå­¦ä¹ å‹æ£€ç´¢åŠŸèƒ½ï¼Œv0.5.0 å°†å®ç°**åˆ†å¸ƒå¼éƒ¨ç½²**èƒ½åŠ›ï¼Œæ”¯æŒå¤§è§„æ¨¡é›†ç¾¤éƒ¨ç½²ã€è´Ÿè½½å‡è¡¡ã€æœåŠ¡å‘ç°å’Œæ•…éšœè½¬ç§»ï¼Œä½¿ LangChain-Go èƒ½å¤Ÿæ”¯æ’‘ä¼ä¸šçº§è§„æ¨¡çš„åº”ç”¨ã€‚

### æ ¸å¿ƒç›®æ ‡

1. **é›†ç¾¤æ”¯æŒ**: å¤šèŠ‚ç‚¹é›†ç¾¤ç®¡ç†
2. **è´Ÿè½½å‡è¡¡**: æ™ºèƒ½è¯·æ±‚åˆ†å‘
3. **æœåŠ¡å‘ç°**: è‡ªåŠ¨èŠ‚ç‚¹æ³¨å†Œå’Œå‘ç°
4. **åˆ†å¸ƒå¼ç¼“å­˜**: è·¨èŠ‚ç‚¹å…±äº«ç¼“å­˜
5. **æ•…éšœè½¬ç§»**: è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œæ¢å¤

---

## ğŸ¯ æŠ€æœ¯æ¶æ„

### ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Load Balancer                      â”‚
â”‚            (Round Robin / Least Conn)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚       â”‚       â”‚               â”‚
     â–¼       â–¼       â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1  â”‚ â”‚ Node 2  â”‚ â”‚ Node 3  â”‚ â”‚ Node N  â”‚
â”‚         â”‚ â”‚         â”‚ â”‚         â”‚ â”‚         â”‚
â”‚ LLM     â”‚ â”‚ LLM     â”‚ â”‚ LLM     â”‚ â”‚ LLM     â”‚
â”‚ RAG     â”‚ â”‚ RAG     â”‚ â”‚ RAG     â”‚ â”‚ RAG     â”‚
â”‚ Cache   â”‚ â”‚ Cache   â”‚ â”‚ Cache   â”‚ â”‚ Cache   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚            â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚
         â–¼                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Service  â”‚    â”‚ Distributed  â”‚
   â”‚Discovery â”‚    â”‚   Cache      â”‚
   â”‚ (Consul) â”‚    â”‚   (Redis)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Vector DB  â”‚
                   â”‚  (Sharded)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

1. **èŠ‚ç‚¹ç®¡ç†å™¨** (Node Manager)
2. **è´Ÿè½½å‡è¡¡å™¨** (Load Balancer)
3. **æœåŠ¡å‘ç°** (Service Discovery)
4. **åˆ†å¸ƒå¼ç¼“å­˜** (Distributed Cache)
5. **å¥åº·æ£€æŸ¥** (Health Checker)
6. **æ•…éšœè½¬ç§»** (Failover Manager)
7. **åˆ†ç‰‡ç®¡ç†** (Shard Manager)

---

## ğŸ“‹ è¯¦ç»†è®¾è®¡

### Phase 1: èŠ‚ç‚¹ç®¡ç†ä¸æœåŠ¡å‘ç° (3-4 å¤©)

#### ç›®æ ‡

å®ç°èŠ‚ç‚¹æ³¨å†Œã€å‘ç°å’Œç®¡ç†ã€‚

#### æ ¸å¿ƒæ¥å£

```go
// pkg/cluster/node/manager.go

package node

import (
    "context"
    "time"
)

// NodeManager èŠ‚ç‚¹ç®¡ç†å™¨
type NodeManager interface {
    // æ³¨å†ŒèŠ‚ç‚¹
    RegisterNode(ctx context.Context, node *Node) error
    
    // æ³¨é”€èŠ‚ç‚¹
    UnregisterNode(ctx context.Context, nodeID string) error
    
    // è·å–èŠ‚ç‚¹
    GetNode(ctx context.Context, nodeID string) (*Node, error)
    
    // åˆ—å‡ºæ‰€æœ‰èŠ‚ç‚¹
    ListNodes(ctx context.Context, filter NodeFilter) ([]*Node, error)
    
    // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
    UpdateNodeStatus(ctx context.Context, nodeID string, status NodeStatus) error
    
    // å¿ƒè·³
    Heartbeat(ctx context.Context, nodeID string) error
    
    // ç›‘å¬èŠ‚ç‚¹å˜åŒ–
    Watch(ctx context.Context) (<-chan NodeEvent, error)
}

// Node èŠ‚ç‚¹ä¿¡æ¯
type Node struct {
    ID         string            `json:"id"`
    Name       string            `json:"name"`
    Address    string            `json:"address"`
    Port       int               `json:"port"`
    Status     NodeStatus        `json:"status"`
    Roles      []NodeRole        `json:"roles"`
    Capacity   Capacity          `json:"capacity"`
    Load       Load              `json:"load"`
    Metadata   map[string]string `json:"metadata"`
    RegisterAt time.Time         `json:"register_at"`
    LastSeen   time.Time         `json:"last_seen"`
}

// NodeStatus èŠ‚ç‚¹çŠ¶æ€
type NodeStatus string

const (
    StatusOnline  NodeStatus = "online"
    StatusOffline NodeStatus = "offline"
    StatusBusy    NodeStatus = "busy"
    StatusDraining NodeStatus = "draining"  // æ­£åœ¨æ’ç©ºï¼Œä¸æ¥å—æ–°è¯·æ±‚
)

// NodeRole èŠ‚ç‚¹è§’è‰²
type NodeRole string

const (
    RoleMaster NodeRole = "master"  // ä¸»èŠ‚ç‚¹
    RoleWorker NodeRole = "worker"  // å·¥ä½œèŠ‚ç‚¹
    RoleCache  NodeRole = "cache"   // ç¼“å­˜èŠ‚ç‚¹
)

// Capacity å®¹é‡ä¿¡æ¯
type Capacity struct {
    MaxConnections int     `json:"max_connections"`
    MaxQPS         int     `json:"max_qps"`
    MaxMemoryMB    int     `json:"max_memory_mb"`
    MaxGoroutines  int     `json:"max_goroutines"`
}

// Load è´Ÿè½½ä¿¡æ¯
type Load struct {
    CurrentConnections int     `json:"current_connections"`
    CurrentQPS         float64 `json:"current_qps"`
    MemoryUsageMB      int     `json:"memory_usage_mb"`
    CPUUsagePercent    float64 `json:"cpu_usage_percent"`
    GoroutineCount     int     `json:"goroutine_count"`
}

// NodeEvent èŠ‚ç‚¹äº‹ä»¶
type NodeEvent struct {
    Type      EventType `json:"type"`
    Node      *Node     `json:"node"`
    Timestamp time.Time `json:"timestamp"`
}

type EventType string

const (
    EventNodeJoined  EventType = "joined"
    EventNodeLeft    EventType = "left"
    EventNodeUpdated EventType = "updated"
)
```

#### æœåŠ¡å‘ç°å®ç°

```go
// pkg/cluster/discovery/consul.go

package discovery

import (
    "context"
    "github.com/hashicorp/consul/api"
    "github.com/zhucl121/langchain-go/pkg/cluster/node"
)

// ConsulDiscovery Consul æœåŠ¡å‘ç°
type ConsulDiscovery struct {
    client *api.Client
    config ConsulConfig
}

// ConsulConfig Consul é…ç½®
type ConsulConfig struct {
    Address     string
    Datacenter  string
    ServiceName string
    Tags        []string
    CheckTTL    time.Duration
}

// NewConsulDiscovery åˆ›å»º Consul æœåŠ¡å‘ç°
func NewConsulDiscovery(config ConsulConfig) (*ConsulDiscovery, error) {
    clientConfig := api.DefaultConfig()
    clientConfig.Address = config.Address
    
    client, err := api.NewClient(clientConfig)
    if err != nil {
        return nil, err
    }
    
    return &ConsulDiscovery{
        client: client,
        config: config,
    }, nil
}

// RegisterNode æ³¨å†ŒèŠ‚ç‚¹
func (d *ConsulDiscovery) RegisterNode(ctx context.Context, n *node.Node) error {
    registration := &api.AgentServiceRegistration{
        ID:      n.ID,
        Name:    d.config.ServiceName,
        Address: n.Address,
        Port:    n.Port,
        Tags:    d.buildTags(n),
        Meta:    n.Metadata,
        Check: &api.AgentServiceCheck{
            TTL:                            d.config.CheckTTL.String(),
            DeregisterCriticalServiceAfter: "30s",
        },
    }
    
    return d.client.Agent().ServiceRegister(registration)
}

// ListNodes åˆ—å‡ºæ‰€æœ‰èŠ‚ç‚¹
func (d *ConsulDiscovery) ListNodes(ctx context.Context, filter node.NodeFilter) ([]*node.Node, error) {
    services, _, err := d.client.Health().Service(d.config.ServiceName, "", true, nil)
    if err != nil {
        return nil, err
    }
    
    nodes := make([]*node.Node, 0, len(services))
    for _, service := range services {
        n := d.serviceToNode(service)
        if filter.Match(n) {
            nodes = append(nodes, n)
        }
    }
    
    return nodes, nil
}

// Watch ç›‘å¬èŠ‚ç‚¹å˜åŒ–
func (d *ConsulDiscovery) Watch(ctx context.Context) (<-chan node.NodeEvent, error) {
    eventCh := make(chan node.NodeEvent, 100)
    
    go func() {
        defer close(eventCh)
        
        var lastIndex uint64
        for {
            select {
            case <-ctx.Done():
                return
            default:
                services, meta, err := d.client.Health().Service(
                    d.config.ServiceName,
                    "",
                    true,
                    &api.QueryOptions{
                        WaitIndex: lastIndex,
                        WaitTime:  30 * time.Second,
                    },
                )
                if err != nil {
                    time.Sleep(5 * time.Second)
                    continue
                }
                
                lastIndex = meta.LastIndex
                
                // æ£€æµ‹å˜åŒ–
                for _, service := range services {
                    n := d.serviceToNode(service)
                    eventCh <- node.NodeEvent{
                        Type:      node.EventNodeUpdated,
                        Node:      n,
                        Timestamp: time.Now(),
                    }
                }
            }
        }
    }()
    
    return eventCh, nil
}
```

#### ä»»åŠ¡æ¸…å•

- [ ] å®šä¹‰èŠ‚ç‚¹ç®¡ç†æ¥å£
- [ ] å®ç° Consul æœåŠ¡å‘ç°
- [ ] å®ç° Etcd æœåŠ¡å‘ç°ï¼ˆå¯é€‰ï¼‰
- [ ] å®ç°èŠ‚ç‚¹å¥åº·æ£€æŸ¥
- [ ] å®ç°èŠ‚ç‚¹ç›‘å¬æœºåˆ¶
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

---

### Phase 2: è´Ÿè½½å‡è¡¡ (3-4 å¤©)

#### ç›®æ ‡

å®ç°æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼Œåˆç†åˆ†å‘è¯·æ±‚ã€‚

#### æ ¸å¿ƒå®ç°

```go
// pkg/cluster/balancer/balancer.go

package balancer

import (
    "context"
    "github.com/zhucl121/langchain-go/pkg/cluster/node"
)

// LoadBalancer è´Ÿè½½å‡è¡¡å™¨
type LoadBalancer interface {
    // é€‰æ‹©èŠ‚ç‚¹
    SelectNode(ctx context.Context, req *Request) (*node.Node, error)
    
    // æ›´æ–°èŠ‚ç‚¹åˆ—è¡¨
    UpdateNodes(nodes []*node.Node)
    
    // è®°å½•è¯·æ±‚ç»“æœ
    RecordResult(nodeID string, success bool, latency time.Duration)
}

// Request è¯·æ±‚ä¿¡æ¯
type Request struct {
    ID       string
    Type     RequestType
    Size     int64
    Metadata map[string]string
}

type RequestType string

const (
    RequestTypeLLM       RequestType = "llm"
    RequestTypeRetrieval RequestType = "retrieval"
    RequestTypeEmbedding RequestType = "embedding"
)

// RoundRobinBalancer è½®è¯¢è´Ÿè½½å‡è¡¡
type RoundRobinBalancer struct {
    nodes   []*node.Node
    current uint32
    mu      sync.RWMutex
}

// SelectNode é€‰æ‹©èŠ‚ç‚¹
func (b *RoundRobinBalancer) SelectNode(ctx context.Context, req *Request) (*node.Node, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()
    
    if len(b.nodes) == 0 {
        return nil, ErrNoAvailableNodes
    }
    
    index := atomic.AddUint32(&b.current, 1) % uint32(len(b.nodes))
    return b.nodes[index], nil
}

// LeastConnectionBalancer æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡
type LeastConnectionBalancer struct {
    nodes       []*node.Node
    connections map[string]int
    mu          sync.RWMutex
}

// SelectNode é€‰æ‹©èŠ‚ç‚¹
func (b *LeastConnectionBalancer) SelectNode(ctx context.Context, req *Request) (*node.Node, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()
    
    if len(b.nodes) == 0 {
        return nil, ErrNoAvailableNodes
    }
    
    var selected *node.Node
    minConn := int(^uint(0) >> 1)
    
    for _, n := range b.nodes {
        conn := b.connections[n.ID]
        if conn < minConn {
            minConn = conn
            selected = n
        }
    }
    
    b.connections[selected.ID]++
    return selected, nil
}

// WeightedBalancer åŠ æƒè´Ÿè½½å‡è¡¡
type WeightedBalancer struct {
    nodes   []*node.Node
    weights []int
    mu      sync.RWMutex
}

// SelectNode é€‰æ‹©èŠ‚ç‚¹ï¼ˆåŸºäºæƒé‡ï¼‰
func (b *WeightedBalancer) SelectNode(ctx context.Context, req *Request) (*node.Node, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()
    
    if len(b.nodes) == 0 {
        return nil, ErrNoAvailableNodes
    }
    
    // è®¡ç®—æ€»æƒé‡
    totalWeight := 0
    for _, w := range b.weights {
        totalWeight += w
    }
    
    // éšæœºé€‰æ‹©
    rand := rand.Intn(totalWeight)
    cumulative := 0
    
    for i, w := range b.weights {
        cumulative += w
        if rand < cumulative {
            return b.nodes[i], nil
        }
    }
    
    return b.nodes[0], nil
}

// ConsistentHashBalancer ä¸€è‡´æ€§å“ˆå¸Œè´Ÿè½½å‡è¡¡
type ConsistentHashBalancer struct {
    ring       *hashring.HashRing
    nodes      []*node.Node
    virtualNum int  // è™šæ‹ŸèŠ‚ç‚¹æ•°
    mu         sync.RWMutex
}

// SelectNode é€‰æ‹©èŠ‚ç‚¹ï¼ˆåŸºäºä¸€è‡´æ€§å“ˆå¸Œï¼‰
func (b *ConsistentHashBalancer) SelectNode(ctx context.Context, req *Request) (*node.Node, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()
    
    if len(b.nodes) == 0 {
        return nil, ErrNoAvailableNodes
    }
    
    // ä½¿ç”¨è¯·æ±‚ ID ä½œä¸ºå“ˆå¸Œé”®
    nodeID, ok := b.ring.GetNode(req.ID)
    if !ok {
        return nil, ErrNodeNotFound
    }
    
    for _, n := range b.nodes {
        if n.ID == nodeID {
            return n, nil
        }
    }
    
    return nil, ErrNodeNotFound
}

// AdaptiveBalancer è‡ªé€‚åº”è´Ÿè½½å‡è¡¡ï¼ˆåŸºäºèŠ‚ç‚¹è´Ÿè½½ï¼‰
type AdaptiveBalancer struct {
    nodes  []*node.Node
    scores map[string]float64  // èŠ‚ç‚¹å¾—åˆ†
    mu     sync.RWMutex
}

// SelectNode é€‰æ‹©èŠ‚ç‚¹ï¼ˆåŸºäºå®æ—¶è´Ÿè½½ï¼‰
func (b *AdaptiveBalancer) SelectNode(ctx context.Context, req *Request) (*node.Node, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()
    
    if len(b.nodes) == 0 {
        return nil, ErrNoAvailableNodes
    }
    
    var selected *node.Node
    maxScore := 0.0
    
    for _, n := range b.nodes {
        score := b.calculateScore(n)
        if score > maxScore {
            maxScore = score
            selected = n
        }
    }
    
    return selected, nil
}

// calculateScore è®¡ç®—èŠ‚ç‚¹å¾—åˆ†
func (b *AdaptiveBalancer) calculateScore(n *node.Node) float64 {
    // è€ƒè™‘å¤šä¸ªå› ç´ ï¼š
    // 1. CPU ä½¿ç”¨ç‡ï¼ˆæƒé‡ 0.3ï¼‰
    // 2. å†…å­˜ä½¿ç”¨ç‡ï¼ˆæƒé‡ 0.2ï¼‰
    // 3. å½“å‰è¿æ¥æ•°ï¼ˆæƒé‡ 0.3ï¼‰
    // 4. å†å²æˆåŠŸç‡ï¼ˆæƒé‡ 0.2ï¼‰
    
    cpuScore := 1.0 - n.Load.CPUUsagePercent/100.0
    memScore := 1.0 - float64(n.Load.MemoryUsageMB)/float64(n.Capacity.MaxMemoryMB)
    connScore := 1.0 - float64(n.Load.CurrentConnections)/float64(n.Capacity.MaxConnections)
    histScore := b.scores[n.ID]
    
    return 0.3*cpuScore + 0.2*memScore + 0.3*connScore + 0.2*histScore
}
```

#### ä»»åŠ¡æ¸…å•

- [ ] å®ç°è½®è¯¢è´Ÿè½½å‡è¡¡
- [ ] å®ç°æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡
- [ ] å®ç°åŠ æƒè´Ÿè½½å‡è¡¡
- [ ] å®ç°ä¸€è‡´æ€§å“ˆå¸Œè´Ÿè½½å‡è¡¡
- [ ] å®ç°è‡ªé€‚åº”è´Ÿè½½å‡è¡¡
- [ ] å®ç°è¯·æ±‚è·¯ç”±é€»è¾‘
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™æ€§èƒ½æµ‹è¯•
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

---

### Phase 3: åˆ†å¸ƒå¼ç¼“å­˜ (2-3 å¤©)

#### ç›®æ ‡

å®ç°è·¨èŠ‚ç‚¹çš„åˆ†å¸ƒå¼ç¼“å­˜ã€‚

#### æ ¸å¿ƒå®ç°

```go
// pkg/cluster/cache/distributed.go

package cache

import (
    "context"
    "github.com/go-redis/redis/v8"
)

// DistributedCache åˆ†å¸ƒå¼ç¼“å­˜æ¥å£
type DistributedCache interface {
    // åŸºç¡€æ“ä½œ
    Get(ctx context.Context, key string) ([]byte, error)
    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error
    Delete(ctx context.Context, key string) error
    Exists(ctx context.Context, key string) (bool, error)
    
    // æ‰¹é‡æ“ä½œ
    MGet(ctx context.Context, keys []string) ([][]byte, error)
    MSet(ctx context.Context, items map[string][]byte, ttl time.Duration) error
    
    // è¿‡æœŸå’Œæ¸…ç†
    Expire(ctx context.Context, key string, ttl time.Duration) error
    Clear(ctx context.Context, pattern string) error
}

// RedisCache Redis åˆ†å¸ƒå¼ç¼“å­˜
type RedisCache struct {
    client  *redis.ClusterClient
    prefix  string
}

// RedisCacheConfig Redis ç¼“å­˜é…ç½®
type RedisCacheConfig struct {
    Addrs    []string
    Password string
    Prefix   string
}

// NewRedisCache åˆ›å»º Redis ç¼“å­˜
func NewRedisCache(config RedisCacheConfig) *RedisCache {
    client := redis.NewClusterClient(&redis.ClusterOptions{
        Addrs:    config.Addrs,
        Password: config.Password,
    })
    
    return &RedisCache{
        client: client,
        prefix: config.Prefix,
    }
}

// Get è·å–ç¼“å­˜
func (c *RedisCache) Get(ctx context.Context, key string) ([]byte, error) {
    fullKey := c.prefix + key
    data, err := c.client.Get(ctx, fullKey).Bytes()
    if err == redis.Nil {
        return nil, ErrCacheNotFound
    }
    return data, err
}

// Set è®¾ç½®ç¼“å­˜
func (c *RedisCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    fullKey := c.prefix + key
    return c.client.Set(ctx, fullKey, value, ttl).Err()
}

// ShardedCache åˆ†ç‰‡ç¼“å­˜ï¼ˆæ”¯æŒæœ¬åœ° + è¿œç¨‹ï¼‰
type ShardedCache struct {
    localCache  Cache
    remoteCache DistributedCache
    shardKey    func(key string) bool  // true = local, false = remote
}

// Get è·å–ç¼“å­˜ï¼ˆå…ˆæœ¬åœ°ï¼Œå†è¿œç¨‹ï¼‰
func (c *ShardedCache) Get(ctx context.Context, key string) ([]byte, error) {
    if c.shardKey(key) {
        // æœ¬åœ°ç¼“å­˜
        if data, err := c.localCache.Get(ctx, key); err == nil {
            return data, nil
        }
    }
    
    // è¿œç¨‹ç¼“å­˜
    return c.remoteCache.Get(ctx, key)
}
```

#### ä»»åŠ¡æ¸…å•

- [ ] å®šä¹‰åˆ†å¸ƒå¼ç¼“å­˜æ¥å£
- [ ] å®ç° Redis Cluster ç¼“å­˜
- [ ] å®ç°åˆ†ç‰‡ç¼“å­˜ç­–ç•¥
- [ ] å®ç°ç¼“å­˜é¢„çƒ­
- [ ] å®ç°ç¼“å­˜å¤±æ•ˆç­–ç•¥
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

---

### Phase 4: æ•…éšœè½¬ç§»ä¸é«˜å¯ç”¨ (3-4 å¤©)

#### ç›®æ ‡

å®ç°è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œè½¬ç§»ã€‚

#### æ ¸å¿ƒå®ç°

```go
// pkg/cluster/failover/manager.go

package failover

import (
    "context"
    "github.com/zhucl121/langchain-go/pkg/cluster/node"
)

// FailoverManager æ•…éšœè½¬ç§»ç®¡ç†å™¨
type FailoverManager interface {
    // ç›‘æ§èŠ‚ç‚¹å¥åº·
    MonitorHealth(ctx context.Context) error
    
    // å¤„ç†èŠ‚ç‚¹æ•…éšœ
    HandleFailure(ctx context.Context, nodeID string) error
    
    // æ¢å¤èŠ‚ç‚¹
    RecoverNode(ctx context.Context, nodeID string) error
    
    // é‡æ–°å¹³è¡¡
    Rebalance(ctx context.Context) error
}

// DefaultFailoverManager é»˜è®¤å®ç°
type DefaultFailoverManager struct {
    nodeManager node.NodeManager
    balancer    balancer.LoadBalancer
    config      FailoverConfig
}

// FailoverConfig æ•…éšœè½¬ç§»é…ç½®
type FailoverConfig struct {
    HealthCheckInterval time.Duration
    FailureThreshold    int
    RecoveryThreshold   int
    AutoRebalance       bool
    RebalanceInterval   time.Duration
}

// MonitorHealth ç›‘æ§èŠ‚ç‚¹å¥åº·
func (m *DefaultFailoverManager) MonitorHealth(ctx context.Context) error {
    ticker := time.NewTicker(m.config.HealthCheckInterval)
    defer ticker.Stop()
    
    failureCount := make(map[string]int)
    
    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        case <-ticker.C:
            nodes, err := m.nodeManager.ListNodes(ctx, node.NodeFilter{
                Status: []node.NodeStatus{node.StatusOnline},
            })
            if err != nil {
                continue
            }
            
            for _, n := range nodes {
                if err := m.checkNodeHealth(ctx, n); err != nil {
                    failureCount[n.ID]++
                    
                    if failureCount[n.ID] >= m.config.FailureThreshold {
                        // æ ‡è®°èŠ‚ç‚¹ä¸ºç¦»çº¿
                        m.nodeManager.UpdateNodeStatus(ctx, n.ID, node.StatusOffline)
                        
                        // è§¦å‘æ•…éšœè½¬ç§»
                        go m.HandleFailure(ctx, n.ID)
                        
                        delete(failureCount, n.ID)
                    }
                } else {
                    // é‡ç½®å¤±è´¥è®¡æ•°
                    delete(failureCount, n.ID)
                }
            }
        }
    }
}

// HandleFailure å¤„ç†èŠ‚ç‚¹æ•…éšœ
func (m *DefaultFailoverManager) HandleFailure(ctx context.Context, nodeID string) error {
    // 1. è®°å½•æ•…éšœæ—¥å¿—
    log.Warnf("Node %s failed, starting failover", nodeID)
    
    // 2. ä»è´Ÿè½½å‡è¡¡å™¨ç§»é™¤èŠ‚ç‚¹
    m.balancer.RemoveNode(nodeID)
    
    // 3. è¿ç§»æ­£åœ¨å¤„ç†çš„è¯·æ±‚
    if err := m.migrateRequests(ctx, nodeID); err != nil {
        return err
    }
    
    // 4. è§¦å‘å‘Šè­¦
    m.sendAlert(nodeID, "Node failure detected")
    
    // 5. å¦‚æœå¯ç”¨è‡ªåŠ¨é‡æ–°å¹³è¡¡
    if m.config.AutoRebalance {
        return m.Rebalance(ctx)
    }
    
    return nil
}

// Rebalance é‡æ–°å¹³è¡¡
func (m *DefaultFailoverManager) Rebalance(ctx context.Context) error {
    nodes, err := m.nodeManager.ListNodes(ctx, node.NodeFilter{
        Status: []node.NodeStatus{node.StatusOnline},
    })
    if err != nil {
        return err
    }
    
    // è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„ç†æƒ³è´Ÿè½½
    totalCapacity := 0
    for _, n := range nodes {
        totalCapacity += n.Capacity.MaxConnections
    }
    
    // é‡æ–°åˆ†é…è´Ÿè½½
    for _, n := range nodes {
        idealLoad := float64(n.Capacity.MaxConnections) / float64(totalCapacity)
        currentLoad := float64(n.Load.CurrentConnections) / float64(n.Capacity.MaxConnections)
        
        if currentLoad > idealLoad*1.2 {
            // èŠ‚ç‚¹è¿‡è½½ï¼Œè¿ç§»éƒ¨åˆ†è¯·æ±‚
            m.migrateFromNode(ctx, n.ID, int((currentLoad-idealLoad)*float64(n.Capacity.MaxConnections)))
        }
    }
    
    return nil
}

// CircuitBreaker ç†”æ–­å™¨
type CircuitBreaker struct {
    state         CircuitState
    failureCount  int
    successCount  int
    config        CircuitBreakerConfig
    mu            sync.RWMutex
    lastStateTime time.Time
}

type CircuitState string

const (
    StateClosed    CircuitState = "closed"     // æ­£å¸¸
    StateOpen      CircuitState = "open"       // ç†”æ–­
    StateHalfOpen  CircuitState = "half_open"  // åŠå¼€
)

type CircuitBreakerConfig struct {
    FailureThreshold int
    SuccessThreshold int
    Timeout          time.Duration
}

// Call æ‰§è¡Œè°ƒç”¨ï¼ˆå¸¦ç†”æ–­ä¿æŠ¤ï¼‰
func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    if cb.state == StateOpen {
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥è½¬æ¢åˆ°åŠå¼€çŠ¶æ€
        if time.Since(cb.lastStateTime) > cb.config.Timeout {
            cb.state = StateHalfOpen
            cb.successCount = 0
        } else {
            return ErrCircuitOpen
        }
    }
    
    err := fn()
    
    if err != nil {
        cb.failureCount++
        if cb.failureCount >= cb.config.FailureThreshold {
            cb.state = StateOpen
            cb.lastStateTime = time.Now()
        }
        return err
    }
    
    // è°ƒç”¨æˆåŠŸ
    cb.failureCount = 0
    if cb.state == StateHalfOpen {
        cb.successCount++
        if cb.successCount >= cb.config.SuccessThreshold {
            cb.state = StateClosed
        }
    }
    
    return nil
}
```

#### ä»»åŠ¡æ¸…å•

- [ ] å®ç°å¥åº·æ£€æŸ¥æœºåˆ¶
- [ ] å®ç°æ•…éšœæ£€æµ‹
- [ ] å®ç°æ•…éšœè½¬ç§»
- [ ] å®ç°è¯·æ±‚è¿ç§»
- [ ] å®ç°ç†”æ–­å™¨
- [ ] å®ç°è‡ªåŠ¨æ¢å¤
- [ ] å®ç°é‡æ–°å¹³è¡¡
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

---

### Phase 5: æµ‹è¯•ã€ä¼˜åŒ–å’Œæ–‡æ¡£ (2-3 å¤©)

#### ä»»åŠ¡æ¸…å•

**æµ‹è¯•**:
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 85%
- [ ] é›†æˆæµ‹è¯•ï¼ˆå¤šèŠ‚ç‚¹é›†ç¾¤ï¼‰
- [ ] æ•…éšœæ³¨å…¥æµ‹è¯•
- [ ] å‹åŠ›æµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•

**ä¼˜åŒ–**:
- [ ] è´Ÿè½½å‡è¡¡æ€§èƒ½ä¼˜åŒ–
- [ ] æ•…éšœè½¬ç§»æ—¶é—´ä¼˜åŒ–
- [ ] ç½‘ç»œé€šä¿¡ä¼˜åŒ–
- [ ] èµ„æºä½¿ç”¨ä¼˜åŒ–

**æ–‡æ¡£**:
- [ ] API æ–‡æ¡£
- [ ] éƒ¨ç½²æŒ‡å—
- [ ] è¿ç»´æ‰‹å†Œ
- [ ] æœ€ä½³å®è·µ
- [ ] æ•…éšœæ’æŸ¥æŒ‡å—

---

## ğŸ“Š äº¤ä»˜æ¸…å•

### ä»£ç äº¤ä»˜

| æ¨¡å— | æ–‡ä»¶æ•° | ä»£ç è¡Œæ•° | æµ‹è¯•è¡Œæ•° | çŠ¶æ€ |
|------|-------|---------|---------|------|
| èŠ‚ç‚¹ç®¡ç† | 6 | 800 | 500 | â³ å¾…å¼€å§‹ |
| è´Ÿè½½å‡è¡¡ | 8 | 1,200 | 700 | â³ å¾…å¼€å§‹ |
| åˆ†å¸ƒå¼ç¼“å­˜ | 5 | 600 | 400 | â³ å¾…å¼€å§‹ |
| æ•…éšœè½¬ç§» | 6 | 1,000 | 600 | â³ å¾…å¼€å§‹ |
| é›†æˆæµ‹è¯• | 4 | 400 | 800 | â³ å¾…å¼€å§‹ |
| **æ€»è®¡** | **29** | **4,000** | **3,000** | **0%** |

### æ–‡æ¡£äº¤ä»˜

1. **V0.5.0_USER_GUIDE.md** - ç”¨æˆ·æŒ‡å—
2. **DISTRIBUTED_DEPLOYMENT_GUIDE.md** - éƒ¨ç½²æŒ‡å—
3. **CLUSTER_OPERATIONS.md** - è¿ç»´æ‰‹å†Œ
4. **LOAD_BALANCING_GUIDE.md** - è´Ÿè½½å‡è¡¡æŒ‡å—
5. **FAILOVER_BEST_PRACTICES.md** - æ•…éšœè½¬ç§»æœ€ä½³å®è·µ

---

## ğŸš€ æŠ€æœ¯äº®ç‚¹

### 1. å¤šç§è´Ÿè½½å‡è¡¡ç­–ç•¥

- è½®è¯¢ï¼ˆRound Robinï¼‰
- æœ€å°‘è¿æ¥ï¼ˆLeast Connectionï¼‰
- åŠ æƒï¼ˆWeightedï¼‰
- ä¸€è‡´æ€§å“ˆå¸Œï¼ˆConsistent Hashï¼‰
- è‡ªé€‚åº”ï¼ˆAdaptiveï¼‰

### 2. è‡ªåŠ¨æ•…éšœè½¬ç§»

- å®æ—¶å¥åº·æ£€æŸ¥
- è‡ªåŠ¨èŠ‚ç‚¹éš”ç¦»
- è¯·æ±‚è‡ªåŠ¨è¿ç§»
- é›¶åœæœºæ—¶é—´

### 3. åˆ†å¸ƒå¼ç¼“å­˜

- Redis Cluster æ”¯æŒ
- æœ¬åœ° + è¿œç¨‹åˆ†å±‚ç¼“å­˜
- ç¼“å­˜é¢„çƒ­
- è‡ªåŠ¨å¤±æ•ˆ

### 4. é«˜å¯ç”¨æ€§

- å¤šèŠ‚ç‚¹å†—ä½™
- è‡ªåŠ¨æ¢å¤
- ç†”æ–­ä¿æŠ¤
- é™çº§ç­–ç•¥

---

## ğŸ“… æ—¶é—´çº¿

**Week 1** (Day 1-5): Phase 1  
**Week 2** (Day 6-10): Phase 2  
**Week 3** (Day 11-14): Phase 3  
**Week 4** (Day 15-18): Phase 4  
**Week 5** (Day 19-21): Phase 5

**é¢„è®¡å‘å¸ƒæ—¥æœŸ**: 2026-04-05

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

### åŠŸèƒ½æŒ‡æ ‡
- [ ] æ”¯æŒå¤šèŠ‚ç‚¹é›†ç¾¤
- [ ] æ”¯æŒ 5 ç§è´Ÿè½½å‡è¡¡ç­–ç•¥
- [ ] è‡ªåŠ¨æ•…éšœè½¬ç§» < 5s
- [ ] æ”¯æŒåˆ†å¸ƒå¼ç¼“å­˜
- [ ] ç†”æ–­å™¨æœ‰æ•ˆå·¥ä½œ

### æ€§èƒ½æŒ‡æ ‡
- **æ•…éšœæ£€æµ‹**: < 10s
- **æ•…éšœè½¬ç§»**: < 5s
- **è´Ÿè½½å‡è¡¡å¼€é”€**: < 1ms
- **é›†ç¾¤ååé‡**: > 10,000 QPS
- **å¯ç”¨æ€§**: > 99.9%

### è´¨é‡æŒ‡æ ‡
- **æµ‹è¯•è¦†ç›–ç‡**: > 85%
- **æ•…éšœæ³¨å…¥æµ‹è¯•**: 100% é€šè¿‡
- **å‹åŠ›æµ‹è¯•**: æ”¯æŒ 100+ èŠ‚ç‚¹

---

## ğŸ” é£é™©å’ŒæŒ‘æˆ˜

### 1. ç½‘ç»œåˆ†åŒº

**é£é™©**: è„‘è£‚é—®é¢˜

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨ Consul/Etcd çš„ä¸€è‡´æ€§ä¿è¯
- å®ç°åˆ†å¸ƒå¼é”
- Quorum æœºåˆ¶

### 2. æ•°æ®ä¸€è‡´æ€§

**é£é™©**: åˆ†å¸ƒå¼ç¼“å­˜æ•°æ®ä¸ä¸€è‡´

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨ Redis Cluster
- å®ç°ç¼“å­˜å¤±æ•ˆç­–ç•¥
- æœ€ç»ˆä¸€è‡´æ€§

### 3. å¤æ‚åº¦å¢åŠ 

**é£é™©**: è¿ç»´å¤æ‚åº¦æå‡

**ç¼“è§£æªæ–½**:
- å®Œæ•´çš„éƒ¨ç½²æ–‡æ¡£
- è‡ªåŠ¨åŒ–è„šæœ¬
- ç›‘æ§å‘Šè­¦

---

## ğŸ’¡ æœªæ¥æ‰©å±•

### v0.5.1 (å¯é€‰)
- Kubernetes é›†æˆ
- Helm Charts
- è‡ªåŠ¨æ‰©ç¼©å®¹

### v0.5.2 (å¯é€‰)
- å¤šæ•°æ®ä¸­å¿ƒæ”¯æŒ
- è·¨åŒºåŸŸå¤åˆ¶
- å…¨çƒè´Ÿè½½å‡è¡¡

---

## ğŸ“š å‚è€ƒèµ„æº

### æœåŠ¡å‘ç°
- [Consul Documentation](https://www.consul.io/docs)
- [Etcd Documentation](https://etcd.io/docs/)

### è´Ÿè½½å‡è¡¡
- [NGINX Load Balancing](https://docs.nginx.com/nginx/admin-guide/load-balancer/)
- [HAProxy Documentation](http://www.haproxy.org/)

### åˆ†å¸ƒå¼ç³»ç»Ÿ
- [Designing Data-Intensive Applications](https://dataintensive.net/)
- [Distributed Systems Theory](https://github.com/aphyr/distsys-class)

---

## âœ… ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¼€å§‹ (2026-03-06)

1. **åˆ›å»º v0.5.0 åˆ†æ”¯**
   ```bash
   git checkout -b feature/v0.5.0-distributed
   ```

2. **è®¾ç½®å¼€å‘ç¯å¢ƒ**
   ```bash
   # å¯åŠ¨ Consul
   docker run -d --name consul -p 8500:8500 consul:latest
   
   # å¯åŠ¨ Redis Cluster
   docker-compose -f docker-compose.redis-cluster.yml up -d
   ```

3. **å¼€å§‹ Phase 1: èŠ‚ç‚¹ç®¡ç†ä¸æœåŠ¡å‘ç°**
   - åˆ›å»º pkg/cluster/ ç›®å½•ç»“æ„
   - å®šä¹‰æ ¸å¿ƒæ¥å£
   - å®ç° Consul é›†æˆ

---

**è®¡åˆ’ç‰ˆæœ¬**: v0.5.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-01-20  
**ä½œè€…**: LangChain-Go Team  
**çŠ¶æ€**: âœ… **å·²æ‰¹å‡†ï¼Œå¾…æ‰§è¡Œ**
