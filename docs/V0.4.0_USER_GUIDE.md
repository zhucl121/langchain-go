# LangChain-Go v0.4.0 ç”¨æˆ·æŒ‡å—

**ç‰ˆæœ¬**: v0.4.0  
**å‘å¸ƒæ—¥æœŸ**: 2026-01-20  
**ä¸»é¢˜**: å®Œæ•´çš„ç›‘æ§ä¸å¯è§‚æµ‹æ€§

---

## ğŸ“– ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ](#ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ)
4. [åˆ†å¸ƒå¼è¿½è¸ª](#åˆ†å¸ƒå¼è¿½è¸ª)
5. [æŒ‡æ ‡æ”¶é›†](#æŒ‡æ ‡æ”¶é›†)
6. [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
7. [ä¸Šä¸‹æ–‡é›†æˆ](#ä¸Šä¸‹æ–‡é›†æˆ)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
9. [FAQ](#faq)

---

## æ¦‚è¿°

LangChain-Go v0.4.0 æä¾›äº†**ç”Ÿäº§çº§çš„ç›‘æ§ä¸å¯è§‚æµ‹æ€§**èƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š

- âœ… **ç»“æ„åŒ–æ—¥å¿—** - åŸºäº Go æ ‡å‡†åº“ `log/slog`
- âœ… **åˆ†å¸ƒå¼è¿½è¸ª** - å®Œæ•´çš„ OpenTelemetry é›†æˆ
- âœ… **æŒ‡æ ‡æ”¶é›†** - Prometheus åŸç”Ÿæ”¯æŒ
- âœ… **æ€§èƒ½åˆ†æ** - CPUã€å†…å­˜ã€Goroutine åˆ†æ
- âœ… **ç»Ÿä¸€ä¸Šä¸‹æ–‡** - è‡ªåŠ¨ä¼ æ’­å’Œè®°å½•

### æ ¸å¿ƒç‰¹æ€§

| åŠŸèƒ½ | æè¿° | çŠ¶æ€ |
|------|------|------|
| ç»“æ„åŒ–æ—¥å¿— | JSON/æ–‡æœ¬æ ¼å¼ï¼Œå¤šçº§åˆ« | âœ… å®Œæ•´ |
| OpenTelemetry | Tracerã€Spanã€å¯¼å‡ºå™¨ | âœ… å®Œæ•´ |
| Prometheus | è‡ªå®šä¹‰æŒ‡æ ‡ã€HTTP ç«¯ç‚¹ | âœ… å®Œæ•´ |
| æ€§èƒ½åˆ†æ | Profilerã€Analyzerã€Benchmark | âœ… å®Œæ•´ |
| ä¸Šä¸‹æ–‡è¿½è¸ª | LLMã€RAGã€Toolã€Agent è¿½è¸ªå™¨ | âœ… å®Œæ•´ |

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
go get github.com/zhucl121/langchain-go
```

### æœ€å°ç¤ºä¾‹

```go
package main

import (
	"context"
	"github.com/zhucl121/langchain-go/pkg/observability"
)

func main() {
	// 1. åˆå§‹åŒ–æ—¥å¿—
	observability.InitGlobalLogger(observability.DefaultLoggerConfig())
	
	// 2. åˆ›å»º Tracer
	tracerConfig := observability.TracerConfig{
		ServiceName: "my-app",
		Endpoint:    "localhost:4317",
	}
	tracerProvider, _ := observability.NewTracerProvider(tracerConfig)
	defer tracerProvider.Shutdown(context.Background())
	
	// 3. åˆ›å»º Metrics
	metricsConfig := observability.MetricsConfig{
		Namespace: "myapp",
	}
	metrics := observability.NewMetricsCollector(metricsConfig)
	
	// 4. åˆ›å»ºå¯è§‚æµ‹æ€§ä¸Šä¸‹æ–‡
	obs := observability.NewObservabilityContext(
		tracerProvider.GetTracer(),
		observability.GetGlobalLogger(),
		metrics,
	)
	
	ctx := observability.WithObservability(context.Background(), obs)
	
	// 5. ä½¿ç”¨
	observability.Info("Application started")
	
	// è¿½è¸ªæ“ä½œ
	err := observability.TrackOperation(ctx, "my-operation", nil, func(ctx context.Context) error {
		// æ‰§è¡Œä¸šåŠ¡é€»è¾‘
		return nil
	})
	
	if err != nil {
		observability.Error("Operation failed", observability.Err(err))
	}
}
```

---

## ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ

### åŸºç¡€ç”¨æ³•

#### åˆ›å»º Logger

```go
config := observability.LoggerConfig{
	Level:         observability.LogLevelInfo,
	Format:        "json",
	Output:        "stdout",
	EnableTraceID: true,
}

logger, err := observability.NewLogger(config)
if err != nil {
	panic(err)
}

// ä½¿ç”¨ logger
logger.Info("User logged in",
	observability.String("user_id", "12345"),
	observability.String("ip", "192.168.1.1"),
)
```

#### å…¨å±€ Logger

```go
// åˆå§‹åŒ–
observability.InitGlobalLogger(observability.DefaultLoggerConfig())

// ä½¿ç”¨
observability.Info("Application started")
observability.Warn("Low memory", observability.Int("available_mb", 512))
observability.Error("Database connection failed", observability.Err(err))
```

### æ—¥å¿—çº§åˆ«

```go
logger.Debug("Detailed debug info", ...)
logger.Info("General information", ...)
logger.Warn("Warning message", ...)
logger.Error("Error occurred", ...)
```

### å­—æ®µç±»å‹

```go
observability.String("key", "value")
observability.Int("count", 42)
observability.Int64("id", int64(123))
observability.Float64("score", 3.14)
observability.Bool("success", true)
observability.Duration("latency", 100*time.Millisecond)
observability.Err(error)
observability.Any("data", complexObject)
```

### å­ Logger

```go
// åˆ›å»ºå¸¦æœ‰å›ºå®šå­—æ®µçš„å­ logger
appLogger := logger.With(
	observability.String("service", "api"),
	observability.String("version", "1.0.0"),
)

// æ‰€æœ‰æ—¥å¿—éƒ½ä¼šåŒ…å«è¿™äº›å­—æ®µ
appLogger.Info("Request received", observability.String("path", "/api/users"))
```

### ä¸Šä¸‹æ–‡æ—¥å¿—

```go
// è‡ªåŠ¨æå– TraceID å’Œ SpanID
ctx, span := tracer.Start(context.Background(), "operation")
defer span.End()

contextLogger := logger.WithContext(ctx)
contextLogger.Info("Processing request") // è‡ªåŠ¨åŒ…å« trace_id å’Œ span_id
```

### æ—¥å¿—è¾“å‡ºé…ç½®

#### è¾“å‡ºåˆ°æ–‡ä»¶

```go
config := observability.LoggerConfig{
	Level:    observability.LogLevelInfo,
	Format:   "json",
	Output:   "file",
	FilePath: "/var/log/myapp/app.log",
}
```

#### è¾“å‡ºåˆ° stdout

```go
config := observability.LoggerConfig{
	Level:  observability.LogLevelInfo,
	Format: "text",
	Output: "stdout",
}
```

---

## åˆ†å¸ƒå¼è¿½è¸ª

### OpenTelemetry é›†æˆ

#### åˆ›å»º TracerProvider

```go
config := observability.TracerConfig{
	ServiceName:    "my-service",
	ServiceVersion: "1.0.0",
	Environment:    "production",
	ExporterType:   "otlp-grpc",  // æˆ– "otlp-http"
	Endpoint:       "localhost:4317",
	SampleRate:     1.0,  // 100% é‡‡æ ·
}

tracerProvider, err := observability.NewTracerProvider(config)
if err != nil {
	panic(err)
}
defer tracerProvider.Shutdown(context.Background())

tracer := tracerProvider.GetTracer()
```

### åˆ›å»º Span

```go
ctx, span := tracer.Start(ctx, "operation-name")
defer span.End()

// è®¾ç½®å±æ€§
helper := observability.NewSpanHelper(span)
helper.SetAttribute("user_id", "12345")
helper.SetAttribute("count", 42)

// è®°å½•äº‹ä»¶
helper.RecordEvent("cache_hit", attribute.String("key", "user:12345"))

// è®°å½•é”™è¯¯
if err != nil {
	helper.RecordError(err)
}

// è®¾ç½®æˆåŠŸçŠ¶æ€
helper.SetSuccess()
```

### è¿½è¸ªè¾…åŠ©å‡½æ•°

#### è¿½è¸ªæ“ä½œ

```go
err := observability.TraceOperation(ctx, tracer, "database-query", 
	func(ctx context.Context, span *observability.SpanHelper) error {
		span.SetAttribute("query", "SELECT * FROM users")
		
		// æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
		result, err := db.Query(ctx, ...)
		
		if err == nil {
			span.SetAttribute("rows", len(result))
		}
		
		return err
	})
```

#### è¿½è¸ª LLM è°ƒç”¨

```go
response, err := observability.TraceLLMCall(ctx, tracer, "openai", "gpt-4",
	func(ctx context.Context) (string, error) {
		return chatModel.Invoke(ctx, messages)
	})
```

#### è¿½è¸ª Tool è°ƒç”¨

```go
result, err := observability.TraceToolCall(ctx, tracer, "calculator",
	func(ctx context.Context) (any, error) {
		return calculator.Run("2+2")
	})
```

---

## æŒ‡æ ‡æ”¶é›†

### Prometheus é›†æˆ

#### åˆ›å»º MetricsCollector

```go
config := observability.MetricsConfig{
	Namespace:            "myapp",
	Subsystem:            "api",
	EnableDefaultMetrics: true,  // å¯ç”¨ Go runtime æŒ‡æ ‡
	HTTPPath:             "/metrics",
	HTTPPort:             "9090",
}

metrics := observability.NewMetricsCollector(config)

// å¯åŠ¨ HTTP æœåŠ¡å™¨
go metrics.StartServer()
```

### è®°å½•æŒ‡æ ‡

#### LLM æŒ‡æ ‡

```go
start := time.Now()
result, err := llm.Invoke(ctx, messages)
duration := time.Since(start)

metrics.RecordLLMCall("openai", "gpt-4", duration, err)
metrics.RecordLLMTokens("openai", "gpt-4", 100, 50)
```

#### RAG æŒ‡æ ‡

```go
start := time.Now()
docs, err := retriever.Search(ctx, query, 10)
duration := time.Since(start)

metrics.RecordRAGQuery("milvus", duration, len(docs), err)
```

#### Agent æŒ‡æ ‡

```go
start := time.Now()
err := agent.Step(ctx)
duration := time.Since(start)

metrics.RecordAgentStep("react", duration, err)
metrics.RecordAgentIteration("react")
```

#### Tool æŒ‡æ ‡

```go
start := time.Now()
result, err := tool.Run(input)
duration := time.Since(start)

metrics.RecordToolCall("calculator", duration, err)
```

### è®¿é—®æŒ‡æ ‡

```bash
curl http://localhost:9090/metrics
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
# HELP langchain_go_llm_calls_total Total number of LLM calls
# TYPE langchain_go_llm_calls_total counter
langchain_go_llm_calls_total{model="gpt-4",provider="openai",status="success"} 42

# HELP langchain_go_llm_call_duration_seconds Duration of LLM calls in seconds
# TYPE langchain_go_llm_call_duration_seconds histogram
langchain_go_llm_call_duration_seconds_bucket{model="gpt-4",provider="openai",le="0.5"} 10
langchain_go_llm_call_duration_seconds_bucket{model="gpt-4",provider="openai",le="1"} 25
...
```

---

## æ€§èƒ½åˆ†æ

### Profiler

#### åŸºæœ¬ç”¨æ³•

```go
config := profiling.DefaultProfilerConfig()
config.EnableCPU = true
config.EnableMemory = true
config.EnableGoroutine = true
config.OutputDir = "./profiles"

profiler, err := profiling.NewProfiler(config)
if err != nil {
	panic(err)
}

// å¼€å§‹åˆ†æ
profiler.Start()

// æ‰§è¡Œéœ€è¦åˆ†æçš„ä»£ç 
// ...

// åœæ­¢åˆ†æ
profiler.Stop()

// profile æ–‡ä»¶ä¿å­˜åœ¨ ./profiles/ ç›®å½•
```

#### åˆ†æç‰¹å®šæ“ä½œ

```go
err := profiling.ProfileOperation(ctx, "my-operation", config,
	func(ctx context.Context) error {
		// æ‰§è¡Œéœ€è¦åˆ†æçš„ä»£ç 
		return doSomething()
	})
```

### Analyzer

#### æ€§èƒ½ç›‘æ§

```go
analyzer := profiling.NewAnalyzer()
analyzer.SetBaseline()

// æ‰§è¡Œæ“ä½œ
doSomeWork()

// åˆ†ææ€§èƒ½
report := analyzer.Analyze()
fmt.Println(report)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
Performance Report
==================

Current Metrics:
  - CPU Count: 8
  - GOMAXPROCS: 8
  - Memory Alloc: 45.23 MB
  - Memory Total Alloc: 152.45 MB
  - Memory Sys: 72.15 MB
  - Heap Alloc: 45.23 MB
  - Heap Sys: 64.00 MB
  - Heap Inuse: 48.12 MB
  - Heap Idle: 15.88 MB
  - Num GC: 12
  - GC Pause: 245.50Î¼s
  - Goroutine Count: 23
  - Timestamp: 2026-01-20T10:30:45Z

Changes (since baseline):
  - Duration: 2.5s
  - Memory Alloc: +15.23 MB
  - Memory Total Alloc: +52.45 MB
  - Memory Sys: +12.15 MB
  - Goroutine Count: +5
  - Num GC: +3

No performance issues detected.
```

### Benchmark

#### åŸºå‡†æµ‹è¯•

```go
report := profiling.RunBenchmark("my-operation", func() {
	// æ‰§è¡Œéœ€è¦æµ‹è¯•çš„ä»£ç 
	for i := 0; i < 10000; i++ {
		result := compute(i)
		_ = result
	}
})

fmt.Printf("Operation took: %s\n", report.Delta.Duration)
fmt.Printf("Memory allocated: %s\n", formatBytes(report.Delta.MemoryAllocDelta))
```

---

## ä¸Šä¸‹æ–‡é›†æˆ

### ç»Ÿä¸€å¯è§‚æµ‹æ€§ä¸Šä¸‹æ–‡

```go
// åˆ›å»ºç»Ÿä¸€çš„å¯è§‚æµ‹æ€§ä¸Šä¸‹æ–‡
obs := observability.NewObservabilityContext(tracer, logger, metrics)
ctx := observability.WithObservability(context.Background(), obs)

// è‡ªåŠ¨ä¼ æ’­åˆ°æ‰€æœ‰æ“ä½œ
err := myFunction(ctx)
```

### æ“ä½œè¿½è¸ªå™¨

#### LLM æ“ä½œ

```go
tracker := observability.StartLLMOperation(ctx, "openai", "gpt-4")
defer tracker.End(err)

result, err := llm.Invoke(ctx, messages)

tracker.SetTokens(100, 50)
```

#### RAG æ“ä½œ

```go
tracker := observability.StartRAGOperation(ctx, "milvus", query)
defer tracker.End(err)

docs, err := retriever.Search(ctx, query, 10)

tracker.SetDocumentCount(len(docs))
```

#### Tool æ“ä½œ

```go
tracker := observability.StartToolOperation(ctx, "calculator", input)
defer tracker.End(err)

result, err := tool.Run(input)

tracker.SetOutput(result)
```

#### Agent æ“ä½œ

```go
tracker := observability.StartAgentOperation(ctx, "react", step)
defer tracker.End(err)

tracker.SetIteration(1)
tracker.SetAction("think")

err := agent.Step(ctx)
```

---

## æœ€ä½³å®è·µ

### 1. ç»Ÿä¸€åˆå§‹åŒ–

åœ¨åº”ç”¨å¯åŠ¨æ—¶ç»Ÿä¸€åˆå§‹åŒ–å¯è§‚æµ‹æ€§ç»„ä»¶ï¼š

```go
func initObservability() (*observability.ObservabilityContext, error) {
	// æ—¥å¿—
	logConfig := observability.LoggerConfig{
		Level:         observability.LogLevelInfo,
		Format:        "json",
		Output:        "stdout",
		EnableTraceID: true,
	}
	if err := observability.InitGlobalLogger(logConfig); err != nil {
		return nil, err
	}
	
	// è¿½è¸ª
	tracerConfig := observability.TracerConfig{
		ServiceName:    os.Getenv("SERVICE_NAME"),
		ServiceVersion: os.Getenv("VERSION"),
		Environment:    os.Getenv("ENV"),
		Endpoint:       os.Getenv("OTEL_ENDPOINT"),
	}
	tracerProvider, err := observability.NewTracerProvider(tracerConfig)
	if err != nil {
		return nil, err
	}
	
	// æŒ‡æ ‡
	metricsConfig := observability.MetricsConfig{
		Namespace: os.Getenv("SERVICE_NAME"),
		EnableDefaultMetrics: true,
	}
	metrics := observability.NewMetricsCollector(metricsConfig)
	
	// å¯åŠ¨ metrics æœåŠ¡å™¨
	go metrics.StartServer()
	
	return observability.NewObservabilityContext(
		tracerProvider.GetTracer(),
		observability.GetGlobalLogger(),
		metrics,
	), nil
}
```

### 2. Context ä¼ æ’­

å§‹ç»ˆé€šè¿‡ context ä¼ é€’å¯è§‚æµ‹æ€§ä¿¡æ¯ï¼š

```go
// âœ… æ­£ç¡®
func ProcessRequest(ctx context.Context, request Request) error {
	// è‡ªåŠ¨è·å–å¯è§‚æµ‹æ€§ä¸Šä¸‹æ–‡
	logger := observability.LogFromContext(ctx)
	
	tracker := observability.StartOperation(ctx, "process_request", nil)
	defer tracker.End(err)
	
	// ...
	
	return nil
}

// âŒ é”™è¯¯
func ProcessRequest(request Request) error {
	// æ— æ³•è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
	observability.Info("Processing request")
	// ...
}
```

### 3. é”™è¯¯å¤„ç†

```go
tracker := observability.StartLLMOperation(ctx, provider, model)
defer func() {
	if r := recover(); r != nil {
		err := fmt.Errorf("panic: %v", r)
		tracker.RecordError(err)
		tracker.End(err)
		panic(r)
	}
}()

result, err := llm.Invoke(ctx, messages)
if err != nil {
	tracker.RecordError(err)
}
tracker.End(err)
```

### 4. æ€§èƒ½å¼€é”€æ§åˆ¶

```go
// ä½¿ç”¨é‡‡æ ·å‡å°‘è¿½è¸ªå¼€é”€
tracerConfig.SampleRate = 0.1  // 10% é‡‡æ ·

// æ—¥å¿—çº§åˆ«æ§åˆ¶
logConfig.Level = observability.LogLevelWarn  // åªè®°å½•è­¦å‘Šå’Œé”™è¯¯

// æˆªæ–­å¤§å­—ç¬¦ä¸²
if len(content) > 1000 {
	content = content[:1000] + "..."
}
logger.Debug("Content", observability.String("content", content))
```

### 5. ç”Ÿäº§ç¯å¢ƒé…ç½®

```go
config := observability.TracerConfig{
	ServiceName:    "production-service",
	ServiceVersion: "1.0.0",
	Environment:    "production",
	ExporterType:   "otlp-grpc",
	Endpoint:       "otel-collector.prod:4317",
	SampleRate:     0.01,  // 1% é‡‡æ ·
	Attributes: map[string]string{
		"region":     "us-west-2",
		"datacenter": "dc1",
	},
}
```

---

## FAQ

### å¦‚ä½•ä¸ Grafana é›†æˆï¼Ÿ

1. æ·»åŠ  Prometheus æ•°æ®æºï¼š

```yaml
datasources:
  - name: LangChain-Go
    type: prometheus
    url: http://localhost:9090
```

2. å¯¼å…¥é¢„å®šä¹‰çš„ Dashboardï¼ˆå¾…æä¾›ï¼‰

### å¦‚ä½•åˆ†æ profile æ–‡ä»¶ï¼Ÿ

```bash
# CPU profile
go tool pprof -http=:8080 ./profiles/cpu_*.prof

# Memory profile
go tool pprof -http=:8080 ./profiles/memory_*.prof

# Goroutine profile
go tool pprof -http=:8080 ./profiles/goroutine_*.prof
```

### æ€§èƒ½å¼€é”€æœ‰å¤šå¤§ï¼Ÿ

- **æ—¥å¿—**: < 1% CPUï¼Œ< 1MB å†…å­˜
- **è¿½è¸ª**: < 3% CPUï¼ˆ100% é‡‡æ ·ï¼‰ï¼Œ< 5MB å†…å­˜
- **æŒ‡æ ‡**: < 1% CPUï¼Œ< 2MB å†…å­˜
- **æ€»è®¡**: < 5% CPUï¼Œ< 10MB å†…å­˜ï¼ˆæ¨èç”Ÿäº§é…ç½®ï¼‰

### å¦‚ä½•ç¦ç”¨å¯è§‚æµ‹æ€§ï¼Ÿ

```go
// ä½¿ç”¨ç©ºå®ç°
type noopLogger struct{}
func (l *noopLogger) Debug(msg string, fields ...Field) {}
func (l *noopLogger) Info(msg string, fields ...Field) {}
// ...

// æˆ–è€…ä½¿ç”¨ nil checks
if obs, ok := observability.FromContext(ctx); ok {
	// åªæœ‰åœ¨æœ‰å¯è§‚æµ‹æ€§ä¸Šä¸‹æ–‡æ—¶æ‰è®°å½•
}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-01-20
